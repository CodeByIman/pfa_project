2202
rpA
8
]LC.sc[
1v91790.4022:viXra
Recent Progress in Conversational AI
Zijun Xue Ruirui Li MingdaLi
UCLA UCLA UCLA
LosAngeles,CA,USA LosAngeles,CA,USA LosAngeles,CA,USA
xuezijun@cs.ucla.edu rrli@cs.ucla.edu limingda@cs.ucla.edu
ABSTRACT qualitygeneral-purposeconversationalAIsystems.Thereinforce-
Conversational artificialintelligence(AI)isbecominganincreas- ment learning method is developed more and more in the task-
inglypopulartopicamongindustryandacademia.Withthefastde- specificorgoal-orientedsystemsbyoptimizingtheoverallperfor-
velopmentofneuralnetwork-basedmodels,alotofneural-based manceofthewholetask.
conversational AIsystem are developed.We will provide abrief Traditionally,theconversationalchatbotconsistsofthreeparts:
reviewoftherecentprogressintheConversationalAI,including the natural language understanding unit, the dialogue manager,
thecommonlyadoptedtechniques,notableworks,famouscompe- andtheresponsegenerationunit.Thenaturallanguageunderstand-
titionsfromacademiaandindustryandwidelyuseddatasets. ing unit [30, 31, 51] is responsible for convert the best interpre-
tationorn-bestinterpretationsofuserspeech[33,41]generated
fromtheautomaticspeechrecognition(ASR)intotheinternalbe-
CCSCONCEPTS
liefrepresentation.Thedialoguemanagerwillberesponsiblefor
‚Ä¢Computersystemsorganization‚ÜíEmbeddedsystems;Re-
theprocesstheinternalrepresentationandpickupaproperpolicy
dundancy;Robotics;‚Ä¢Networks‚ÜíNetworkreliability;
togenerateaproperoutput.Theresponsegenerationunitwillbe
basedonthedialoguemanager‚Äôsbelieftogeneratearesponsefor
KEYWORDS theuser.Itcouldbeatextreply,anorderforahotelorasystem
ConversationalAI,Chatbot,GenerativeModel APIcalletc.
TheconversationalAIcouldbeclassifiedascasualchatorchit-
ACMReferenceFormat: chatAIandtask-orientedAI.Forchit-chatAI,thepurposeofthe
ZijunXue,RuiruiLi,andMingdaLi.2010.RecentProgressinConversa- AIisconductingmeaningfuldiscussionasthedailycasualtalkbe-
tional AI.In Proceedings of ACMConference(Conference‚Äô17). ACM, New tween human beings. These types ofAI usuallydoesn‚Äôt need to
York,NY,USA,Article39,6pages.https://doi.org/0000001.0000001_2 refertodatabaseorexternalinformation.Forthetask-orientedAI,
theuserassumestheAIcanprovidereliabletask-specificinforma-
tionsothatthistypeofAIusuallyrequirestoqueryanexternal
1 INTRODUCTION
databaseorknowledgebase.
ConversationalAIisalong-standingresearchtopic.Bothacademia Inthispaper,wewillmainlyintroducetherecent progressof
andindustryorganizationsshowedgreatinterestforthistypeof conversationalAIwithmorefocusontheneural-basedmethods.
systems.TheconversationalAIsystemhasgreatcommercialvalue Wewillintroduceseveralwidelyappliedneuralnetworkmod-
andinvolvesalotofinterestingquestionsrangingfromnaturallan- elsinconversationalAIinsection2.Wewillintroducetherecent
guageprocessing,speechrecognition,knowledgebasereasoning worksinsection3.Wewillintroduceseveralopenconversational
andhuman-computerinteractiondesignetc.Thereareanumber AIchallengeandpublicdatasetsinsection4.Wewilldrawbrief
of large-scale conversational AI systems had been built,such as concludingremarksinsection5.
Siri,Xiaoice,AlexaandGoogleAssistant.
Recently,withthesurgeofneural-basedmodelsinvariousfields
2 NOTABLEMODELS
[12,19,32,35,50,58],avarietyofneural-basedconversationalAI
systemshavebeendeveloped[2,5,11,24,60,68].Themaintech- Therearetwoprominentclassesofmodelswhicharewidelyadopted
niquesadoptedbyresearchersarethreecategories:thedistributed byvariousconversationalAIsystems.Thefirstclassofmodelisthe
representationofentities,thesequence-to-sequencemodelandthe reinforcement learning model[46]. This type of model is widely
reinforcementlearningframework.Thedistributedrepresentation adopted in task-oriented dialogue models. The second category
isadoptedtorepresenttheinternalstatus,userutterance,andex- is the sequence-to-sequence model which is first introduced by
ternalknowledgetoenablemoreconvenientretrievalandprocess- Sutskeveretal[55].Thesequence-to-sequencemodeliswidelyadopted
ing.Thesequence-to-sequencemodelisappliedtogeneratehigh ingeneral-purposedialoguemodels.
2.1 Reinforcement LearningModel
ACMacknowledgesthatthiscontributionwasauthoredorco-authoredbyanem-
ployee,contractor,oraffiliateoftheUnitedStatesgovernment.Assuch,theUnited DQN[46]isareinforcementlearningframeworkwhichisproposed
Statesgovernmentretainsanonexclusive,royalty-freerighttopublishorreproduce
byMnihetin2013.Thisworkisknownforitssuccessinplating
thisarticle,ortoallowotherstodoso,forgovernmentpurposesonly.
Conference‚Äô17,July2017,Washington,DC,USA Atarigames withoutany predefined dataset.This workinspired
¬©2010AssociationforComputingMachinery. numerouslaterworkbyincorporatingthistechniqueintodiffer-
ACMISBN978-x-xxxx-xxxx-x/YY/MM...$15.00
entscenarios.
https://doi.org/0000001.0000001_2
Conference‚Äô17,July2017,Washington,DC,USA ZijunXue,RuiruiLi,andMingdaLi
LeakGAN[17]isproposedtoaddresstherewardsparsityissue. Gunasekarain[16]triedtomodelthedialogueprocessbysep-
Itfurtherusesfeaturesextractedfromthediscriminatorasastep- aratingthelanguageandlogic.Theauthorusestheclusterofen-
by-stepguidetotrainthegenerator.Itimprovestheperformance tities to replace the original entity. A language model is trained
ofsequencegeneration,especiallyinlongtext. basedonthisabstractrepresentation.Theclusterisgeneratedby
RankGAN[39]claimsthattherichnessinsidethesentencescon- conglomeratethenearbywordembeddings.Thedialogstatesare
strainedbybinarypredictionistoorestrictiveandrelaxesthetrain- alsotrackedinordertoachievehighrelevancewiththequestion.
ing ofthediscriminatortoalearning-to-rank optimizationprob- In[29],Liproposedamethodtoincorporatethereinforcement
lem. learningfordialoggeneration.Thechallengeforadoptingthere-
inforcementlearningindialoggenerationisthedesignofreward
2.2 Sequence-to-sequenceModel function.Inthispaper,theauthorproposedthreeaspectsforthe
designofrewardfunction:informativity(non-repetitiveturns),co-
thelongshort-termmemoryLSTM[22]isatypeofrecurrentneu-
herence,andeaseofanswering(relatedtoforward-lookingfunc-
ralnetworkwhichisdesignedtoprocessthesequentialdata.The
tion).
sequence-to-sequencemodeliswidelyappliedtotheconversational
In [66], the author proposed a reinforcement seq2seq model,
AIsystems.
whichiscalledauserandagentmodelintegrationframework(SAMIA)
Thesequence-to-sequencemodelisproposedbySutskever,Le
to generate the task-oriented dialog. This work is based on the
etal[55].ThismodelutilizestheLSTMstructureanddesignedan
observationthattheasymmetricbehavioroftheroleinthetask-
encoder-decoderstructuretoprocesstheconversationdata.
orienteddialog.Onerole,theuseristrainedbytheseq2seqmodel
SeqGAN[76]appliesadversarialtrainingonsequencegenera-
andanotherrole,theagentistrainedbythereinforcementlearn-
tionunderthereinforcement learningframework.SeqGANmod-
ing.Theyadoptacoffeeorderingdatasettoverifytheeffectiveness
elsthetextgenerationasasequentialdecision-makingtask.The
ofthismodel.
state is previously generated words, the action is the next word
In[49],theauthorproposesahierarchicaldeepreinforcement
to be generated, and the rewards are the feedback derived from
learning framework to solve the composite task-completion dia-
the discriminator. More precisely, the generator, constructed by
loguepolicylearningproblem.Thenotablepointofthispaperis
anLSTMmodel,generatesasequenceofwords.Thegeneratedse-
theproblemisformulatedasaMarkovDecisionProcessandahier-
quenceofwordsispassedtothediscriminatortogeneratereward
archicalreinforcementlearningmethodisusedtotrainadialogue
signals.Thediscriminatorisconstructedbyabinaryclassifier.The
manager.Thedialoguemanagerconsistsofatop-levelmanager,a
binaryclassifiertakessentences fromrealdataaspositiveexam-
plesandtakessentencesgeneratedbyùê∫asnegativeexamples.The subgoalmanager,andaglobalmanagertoensuretheoverallgoal
isfinished.
rewardisdefinedbythecross-entropybetweenthepredicteddis-
In[23],theauthortriestosolvethelackofdataproblemforthe
tributionandtruedistribution.
task-specificproblembyusingatransferlearningmethod.Theau-
3 RECENTWORKS thorclaimsthatthelackoftrainingdataforgoal-orientedsystems
areprevalent.Thetransferlearningmethodcanimprovetheper-
Inthissection,wewillintroduceanumberofrecentattemptincon-
formanceofdistanttasksby20%anddoubletheperformancefor
versationalAIsystem.Wecategorizetheseworksintotwoparts:
closerelatedtasks.
task-orientedsystemandgeneralpurposeconversationalAI.The
In [25,40,57],variousother aspectsand applicationsofgoal-
formeroneisusuallydomain-specificandpotentiallytendtocon-
orienteddialoguesystemisinvestigated.In[52][25]theauthorpro-
sultanexternaldatabaseorknowledgebases.Thelatteroneisthe
posedapersonalizationingoal-orienteddialog.Theauthortriesto
topicswhicharesharedamountdifferenttypesofconversational
modelthepersonalizationasamulti-tasklearningproblem.They
systemsandtheyinvestigatevariousaspectswhichwillaffectthe
alsosuggestasinglemodelwhichsharesfeaturesamongvarious
styleandsatisfactoryofhumanusers.
profilesisbetterthanseparatemodelsforeachprofile.In[53][40],
theauthorproposedanaccelerationtechniquebyusingtheThomp-
3.1 RL-basedmethodandTask-orientedsystem
sonsamplingtoimprovetheefficiencyofthedeepreinforcement
In recent research works, task-oriented dialog system has been learning(DQN). In [54][57], the author investigates how chatbot
modeled as a reinforcement learning system. The reward of the couldbeusedtocoordinateteamwork.Theauthordeployedapro-
systemisdecidedbywhethertheoveralltaskisfinished.Previous totype system to coordinate eight teams to finish create, assign,
evaluation for generative system evaluates the quality of single andkeeptrackofthetasks.Seveninsightsforthefuturedesignof
generated sentence pairwhichdoesn‚Äôttaketheoverall taskinto thechatbotarealsoproposed.
consideration.
In[74],theauthorproposedapartiallyobservedMarkovdeci-
sionprocess(POMDP)foradialogprocess.Thekey pointofthis 3.2 end2endTask-orientedsystem
workisthestatebelieftracingandreinforcementlearning.Itcon-
Fortheend-to-endnetworks,therearetwoprominentcategories.
sists of the language model M and the policy model P. The lan-
Thefirst category[4, 8, 54] is mainly based on the Memory Net-
guagemodelgeneratesabeliefstateandpolicymodelgeneratesa
work[memory].Thesecond categoryisattemptingtoaccessthe
responsebasedontheinternalparameterandthebeliefstatefrom
externallibraryandconvertingtheinputquestionsintosomein-
thelanguagemodel.Theaccumulatedresultswillbeaccumulated
ternalrepresentations.
andevaluatedbytherewardfunction.
RecentProgressinConversationalAI Conference‚Äô17,July2017,Washington,DC,USA
In[67],theauthormodelthetask-orientedproblemasasequence- extraction[63,64,71],abnormalvaluedetection[34]withscalable
to-sequencemappingproblemwhichisaugmentedbythedialogue distributedplatforms[6,15,37,38,65,77]arenecessary.Thedif-
historyandexternalinformation.Thesequence-to-sequencemod- ferentformatofknowledgebasesincludethekey-valuepairsand
elingcangenerateaproperformatoftheresponsewithsomeempty unstructuredtextcorpusetc.
"slots".Theinputwillbeprocessedbytwointernalsystems.The In[42],Loweetalpresentamethodtoutilizetheexternalun-
firstisanLSTMnetworkwhichmodelstheuser‚Äôsintent.Thesec- structuredtextinformationtoimprovetheneural-baseddialogue
ondoneisabelieftrackerwhichismaintainingamultinomialdis- system.Theoriginalsystemisanextensionofadual-encodermodel
tributionoveragivenvalueset.Thepolicynetworkwillaggregate whichencodethecontextandtheresponsebyusingtwoRNNnet-
theintentvalue,beliefvalue,andthedatabaseresulttogenerate works.TheextendedversionconstructsoneRNNcomponenttoen-
theeventualoutput. codetheexternalknowledge.Therelevanceofexternalsentence
In[69],Williametalproposeamodelforthetask-orientedsys- isdecidedbyamodulewhichcombinesthehashingand TF-IDF
temwhichisusinganLSTMtoautomaticallypredictthestateof techniques.
thesystemwhichdoesn‚Äôtrequireexplicitrepresentationorextra In[13],theauthorgeneralizesaseq2seqmodelbyconditioning
belieftracker.TheLSTMcanbeoptimizedbysupervisedlearning onbothconversationhistoryandexternalfactstobuildachatbot
whichrequirestheexperttoprovidethehigh-qualitytrainingdata. whichis fit forthe open-domainsettings. Theexternal datais a
Oritcanguidethereinforcementlearningsystemwhichjustneeds largenumber ofraw text entries fromFoursquare, Wikipediaor
theusers‚Äôinput whichcouldbeaccelerated bysupervisedlearn- Amazonreviews. Thesedataareindexedbythenamedentityas
ing(SL). The author also suggests this system is ready to active thekeys.Eachconversationhistorywillbeprocessedtofindthe
learningstrategieswhichcanboosttheperformanceprominently. mostimportantentityandaretrieve-based methodisadoptedto
In[36],theauthorproposedanLSTM-basedsystemwhichus- findthemostrelevantfacts.Themostrelevantfactsandconversa-
ing the DQN framework to control the noise introduced by the tionhistorywillbeencodedbytheneuralarchitecture.
user.Theauthorremarksthatthismodel‚Äôsdialoguemanagement In [18], Freebase is used as an external knowledge base. The
modulecandirectlyinteractwiththedatabase.Theoverallerror namedentityrecognitionwillbeappliedtoidentifythekeyentity
canalsobereducedduetothesystemstructure. inasentenceandthentherelevantentitywillbeextractedfrom
In[54],theauthorintroducesaneuralnetworkmodelwithre- theknowledgebasewhichenablesthesystemtoanswermorespe-
currentattentionmodeloveralargeexternalmemory.Itistrained cializedquestions.
end-to-endwhichisdifferentfromoriginalMemoryNetowrk[Memory]. In[80],theauthorproposedagenerativedialoguesystemwhich
Thequestionsentenceisrepresentedasabagofwordsandthen canhandletheentitieswhichdonotappearinthetrainingdataset.
convertedtoembeddings.Thesystemusesastackedstructureto Thisworkalsoadoptsanentityextractiontechniquesbutamore
predicttheanswertotheeventualresult.Thissystemcanachieve complexexternalentityselectionfunctionisdesignedsothatitis
acomparableresultintheQAtasksasLSTMorRNNmodels. morerobusttotheunseenentity.Thismethodisalsogoodforthe
In [4], the author uses the memory network for QA into the serendipitieswhichtendtopunishsimilarresults.
dialog.Theauthorusesastackedstructureofthememorymatrix In[75],theauthoristryingtoaugmentthechit-chatdialogue
whichissimilarto[54].Thehistoryofthedialogueisstoredbythe byusingthecommonsenseknowledge.
network.Thisisnotagenerativemodelandtheresultisselected
fromagivensetofanswers.Theresultofthismethodisstillnot
3.3 Fine-aspectsmodelsinConversationalAI
perfectwhichisindicatedbytheauthors.
3.3.1 DialogueStateTracking. Thedialoguestatetracking(DST)[42][20]
In [8], theauthorproposedanew benchmark toevaluate the
iswelladoptedinvariousdialoguesystemstotrackthestateofon-
performanceoftheend-to-end dialoguesystemsand testedase-
goingconversations.Itisawell-studiedtopicindialogueprocess-
ries models on this new dataset. This new dataset consists of a
ing. Thedialoguestatetrackingisimplemented byvarioustech-
variety of scenario including factual questions from movie data-
niques.Withtheboomingoftheneuralnetwork,RNNiswidely
base,personalizationquestionsfromthemovieLens,shortconver-
adoptedtomodeltheinternalbeliefofthedialogue.Thedialogue
sations,andnaturaldialoguefromtheReddit.Thisdatasetcovers
statetrackinghasbeenformalizedasasequentialannotationprob-
75kmovieentitiesandcontains3.5Mtrainingexamples.Basedon
lem.
theauthor‚Äôstest,theMemoryNetwork[memory]hasthebestover-
In[21],Hendersonetalproposeaword-basedtrackingmethod
allperformance.
whichmapsdirectlyfromdialoguestatetothedialoguestatewith-
3.2.1 Externaldatabase andknowledgebases. Inordertocon- outusing any decoding steps. This method is based on an RNN
struct a task-oriented dialogue system, the external database ac- structurewhichisabletogeneralizetounseendialoguestate.This
cessisoftennecessary.Traditionally,researcherswillusethesym- methodisabletoachieveconsistentlygoodresultamongdifferent
bolicrepresentationtoconvertthesentencesintodatabasequeries. metrics.
With the fast growth of the neural-based dialogue systems, the In[48],theauthorproposedmethodfortrainingmulti-domain
neuralmodelisalsowidelytestedintheeffortofintegratingex- RNNdialoguestatetrackingmodels.Thisprocedurewillfirstuse
ternaldatabasesandknowledgebasesintodialoguesystems.Var- acompletedatasetwhichcontainsalltypesofdatatotrainagen-
ioustypesofknowledgebasesanddatabaseshavebeenexplored. eralmodel.Thenthemodelwillbetrainedbythedomain-specific
[7,10,13,18,42,59,72,73,75,80].Toobtainahigh-qualitydata- datasettogainthespecializedfeatureswhilestillkeepthegeneral
base,pre-processingstepssuchasdatacleaning[61,62,70],entity cross-domainfeatures.Theexperimentshowsthesemodelshave
Conference‚Äô17,July2017,Washington,DC,USA ZijunXue,RuiruiLi,andMingdaLi
arobustperformanceacrossalldomains.Theyusuallyoutperform Inthispaper,theauthorproposedaspeakermodelandaspeaker-
themodelsthattrainedontarget-domainalone. addresseemodeltomaintaintheconsistencyoftheconversation.
In[26],theauthorproposedastatelineagetrackingmethodin DiversityThediversityisalsoanimportantaspectofthecon-
whichthestateofadialogueisrepresentedasadynamicgrowing versation.Aconversationcouldbeveryboringiftheresponseis
treestructure.Thisstatisticalsolutionenablesthemodeltoprocess toogenericoruniversal.Forexample,ifachatbotreplies"Idon‚Äôt
morecomplexgoal. know" or "This is a good question", the quality of conversation
ishindered.In[30][27],Liproposedanewobjectivefunctionfor
3.3.2 Fine-grainedresponsemodel. RL-baseddialogsystemsand theseq2seqmodel,AMaximumMutualInformation(MMI)tore-
end2enddialogsystemshaveacommonshortage.Theyoversim- placethetraditionallog-likelihoodfunctionwhichoftenyieldsto
plifythedialoginourdailylife.Alotofresearchisaimingatim- genericresponses.
provingthegenerateddialogqualitybyintroducingvariouscon- Zhao in [78] proposed a conditional variational autoencoder
straintswhicharehintedbyrealwordconversation‚Äôsintuitionand model(CVAE) to generate more informative responses. He is at-
experiences. Suchaspectsinclude emotion,persona, diversity or temptingtomodeltheconversationprocessasaone-to-manyprob-
conversation‚Äôscontext.[reference]. leminthediscourselevel.
ContextAconversationisanalternatingspeakingprocessand In[47],Mouproposedaninterestingmethodwhichgenerates
theinformationisflowinginbetweenthetwodialogparties.Con- amostrelevantnounaboutthequestion.Theanswerwillbegen-
text isusuallyreferred as theinformation which had been men- eratedbasedonthisnoun.
tionedpreviously.Clearly,thecontextisverycriticalforresponse Emotion The emotion is a very important aspect of human-
generation. Otherwise, the conversation tends to be off-topic or computerinterfacedesign.ItisalsotrueforconversationalAIwhich
irrelevantatall. isaprominenttypeofinterfaceinbetweenhumanandmachine.
In[53],theauthorimplementsarecurrentlanguagemodel(RLM) The emotioncouldbeexpressed bya certainresponse styleand
which incorporate the context information to generate the new wordselection.
sentences.Threealgorithmsarepresentedinthepaper.Firstone In[14],GhoshmodeledtheaffectionbyusinganLSTMmodel
trainstheRLMbyusingtheconcatenationofinput,context,and which is conditioned on several predefined affection categories.
output.Inthegenerationphase,onlyinputandcontextarefeeding Theaffectioncategoryisinferredbythewordinthequestion.There
intotheRLMtogenerateaproperhiddenstateofRLMandtheout- isalsoanintensityvariabletocontrolthestrengthoftheemotional
putisgeneratedbythehiddenstate.Thesecondmethodmapsthe words.
inputandcontextfromabagofwordstoafixedlengthvectorby In [79], the author proposed an algorithm to generate the re-
usingafeed-forwardneuralnetworkandupdatethehiddenstate sponsebasedonpredefinedcategories.Threeaspectsareconsid-
byusingsuchvectors.Thethirdmethodmapsinputandcontext eredtogenerateaproperemotionalresponse.Firstoneisthehigh-
intotwoseparatebagstogeneratevectors. levelabstractionofemotionexpressionwhichismodeledbyem-
In[9],theauthorintroducedanLSTMstructureplusattention beddingemotioncategories.Thesecondiscapturingtheinternal
mechanismtoencodetheinputandthecontexttogeneratedesir- emotionalstatesandthelastoneusesexplicitemotionexpression
ableoutputsentences.Onenoticeablepointofthisworkisusing withexternalemotionvocabulary.
ann-gramrerankertogeneratetheoutputwhichencouragesout- In[3],Asgharutilizesahand-craftedaffectivedictionarywhich
putshowoverlapwiththecontext.Anothernotableworkis[52]. mapsover10,000Englishwordsintoa3Dspaceofvalence,arousal,
Inthispaper,theauthorproposedaLatentVariableHierarchical anddominance. Several different lossfunctionsareattemptedto
EncodeDecoderModelwhichincorporateslatentvariablesinthe optimizetheperformancesuchasminimizingaffectiondissonance,
decoder. maximizingaffectiondissonance,maximizingaffectivecontent,af-
PersonaThepersonaisanotherimportantdimension incon- fectivelydiversedecodinganddiversebeamsearch.
versationalAIdesign.Whenwehaveaflatassumptionoftheper-
sonaoftheAI,ittendstogenerateimpersonalresponses.Forex-
ample,whenausertasksaboutfrustratedexperiencesinbrowsing
the Internet, a vanilla chatbot will reply "Thanks for your infor- 4 EXISTINGDATASETSANDBENCHMARKS
mation"or "Ihave no ideawhat areyou talking about".A robot
4.1 Commondatasets
trainedwithaspecificpersonawillbelikelytogiveameaningful
response, suchas"Sorrytohear aboutit.Itisusuallycausedby OpenSubtitles[56]isapublicdatasetwhichincludesthesubtitles
browsercache.Haveyoucleanedyourbrowsercacheyet?" for movies. It includes 59 kinds of languages for more than ten
In[45]Luanetal buildasystemwithtwodifferent roles,the thousandsmovies.
questioner,andtherequestertotraintheRNNmodel.Topicmod- Ubuntu Dialogue Corpus,mentioned in [43],includes conver-
elingisintroducedtorepresentthecontextofdialogue.In[27][44], sationsextractedfromchatsaboutUbuntutechnicalsupport.The
theauthoradoptsajointtrainingstrategyfortwomodelswhich datasetcanbeaccessedandgeneratedfollowingtheinstructions
sharethesameparametersinthedecodinglayer.Thefirstmodelis [1] easily. Theconversation ismulti-turnand can involve multi-
trainedonthegeneralconversationdataandthesecondmodelis pleparticipants.Thereareabout936,000dialoguesand100,000,000
trainedonthetask-specificdatasetswhichaimtoreducenonsen- containedinthedataset[43].Theleastturnforeachdialogueis3
sicalgeneralresponses.In[28][28],Liproposedapersona-based whiletheaverageis7.71asthestatsinformationinTable1of[43].
modelwhichaimstoimprovetheconsistencyoftheconversation.
RecentProgressinConversationalAI Conference‚Äô17,July2017,Washington,DC,USA
4.2 Opencompetitions [17] JiaxianGuo,SidiLu,HanCai,WeinanZhang,YongYu,andJunWang.2017.
LongTextGenerationviaAdversarialTrainingwithLeakedInformation.arXiv
Chatbotdevelopmentchallenge,hostedbyindustrialandacademia,
preprintarXiv:1709.08624(2017).
suchasAmazonAlexaPrize,NIPSConversationalIntelligenceChal- [18] SangdoHan,JeesooBang,SeonghanRyu,andGaryGeunbaeLee.2015.Exploit-
lengeandDSTC6DialogSystemsTechnologyChallengearepreva- ingknowledgebasetogenerateresponsesfornaturallanguagedialoglistening
agents.InProceedingsofthe16thAnnualMeetingoftheSpecialInterestGroupon
lent. DiscourseandDialogue.129‚Äì133.
AlexaPrizeisheldbyAmazonsince2017.Thechallengeisbuild- [19] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016. Deepresidual
learningforimagerecognition.InProceedingsoftheIEEEconferenceoncomputer
ingachatbotwhichcanconductaconversationwithhumanbeing
visionandpatternrecognition.770‚Äì778.
onpopularsocialtopicsformorethan20minutes. [20] MatthewHenderson.2015. Machinelearningfordialogstatetracking:Are-
view.InProc.ofTheFirstInternationalWorkshoponMachineLearninginSpoken
5 CONCLUDINGREMARKS LanguageProcessing.
[21] MatthewHenderson,BlaiseThomson,andSteveYoung.2014.Word-baseddia-
Inthispaper,webrieflyconcludethecurrentprogressofthecon- logstatetrackingwithrecurrentneuralnetworks.InProceedingsofthe15thAn-
nualMeetingoftheSpecialInterestGrouponDiscourseandDialogue(SIGDIAL).
versationalAI.Deeplearningtechniquessuchassequence-to-sequence 292‚Äì299.
modelandreinforcementlearningarewidelyadoptedinbothgeneral- [22] Sepp Hochreiter and J√ºrgen Schmidhuber. 1997. Long Short-
Term Memory. Neural Comput. 9, 8 (Nov. 1997), 1735‚Äì1780.
purposeandgoal-orientedconversationalAI.Withtheadoptionof
https://doi.org/10.1162/neco.1997.9.8.1735
thedistributedrepresentation,theinternalstatetrackingproblem [23] VladimirIlievski,ClaudiuMusat,AndreeaHossmann,andMichaelBaeriswyl.
hasfoundanewpromisingdirection.Theincorporationofexter- 2018.Goal-OrientedChatbotDialogManagementBootstrappingwithTransfer
Learning.arXivpreprintarXiv:1802.00500(2018).
nalinformationisstillabigchallenge.Howtoincorporatetheex-
[24] ChinnadhuraiSankarIulianV.Serban.2017.TheOctopusApproachtotheAlexa
ternalinformationwiththeneural-basedconversationalAIwillbe Competition:ADeepEnsemble-basedSocialbot.AlexaPrizeProceedings(2017).
avaluablequestion. [25] ChaitanyaKJoshi,FeiMi,andBoiFaltings.2017. PersonalizationinGoal-
OrientedDialog.arXivpreprintarXiv:1706.07503(2017).
[26] SungjinLeeandAmandaStent.2016. Tasklineages:Dialogstatetrackingfor
REFERENCES flexibleinteraction.InProceedingsofthe17thAnnualMeetingoftheSpecialIn-
terestGrouponDiscourseandDialogue.11‚Äì21.
[1] 2017.UbuntuDialogueCorpusv2.0.https://github.com/rkadlec/ubuntu-ranking-dataset-creator
[27] JiweiLi,MichelGalley,ChrisBrockett,JianfengGao,andBillDolan.2015. A
[2] CervoneAlessandra,TortoretoGiuliano,MezzaStefano,GambiEnrico,Riccardi
diversity-promotingobjectivefunctionforneuralconversationmodels. arXiv
Giuseppe,etal.2017. RovingMind:abalancingactbetweenopen‚Äìdomain
preprintarXiv:1510.03055(2015).
andengagingdialoguesystems.InAlexaPrize,Vol.1.https://developer.amazon.
[28] JiweiLi,MichelGalley,ChrisBrockett,GeorgiosPSpithourakis,JianfengGao,
com/alexaprize/proceedings.
andBillDolan.2016.Apersona-basedneuralconversationmodel.arXivpreprint
[3] NabihaAsghar,PascalPoupart,JesseHoey,XinJiang,andLiliMou.2018. Af-
arXiv:1603.06155(2016).
fectiveNeuralResponseGeneration.InEuropeanConferenceonInformationRe-
[29] JiweiLi,WillMonroe,AlanRitter,MichelGalley,JianfengGao,andDanJuraf-
trieval.Springer,154‚Äì166.
sky.2016.Deepreinforcementlearningfordialoguegeneration.arXivpreprint
[4] AntoineBordes,Y-LanBoureau,andJasonWeston.2016. Learningend-to-end
arXiv:1606.01541(2016).
goal-orienteddialog.arXivpreprintarXiv:1605.07683(2016).
[30] MingdaLi.2020. EfficientLatentSemanticExtractionfromCrossDomainData
[5] KevinKBowden,JiaqiWu,ShereenOraby,AmitaMisra,andMarilynWalker.
withDeclarativeLanguage.UniversityofCalifornia,LosAngeles.
2018. Slugbot:AnApplicationofaNovelandScalableOpenDomainSocialbot
[31] MingdaLi,XinyueLiu,WeitongRuan,LucaSoldaini,WaelHamza,andCheng-
Framework.arXivpreprintarXiv:1801.01531(2018).
weiSu.2020. Multi-tasklearningofspokenlanguageunderstandingbyinte-
[6] AriyamDas,YoufuLi,JinWang,MingdaLi,andCarloZaniolo.2019.Bigdataap-
gratingn-besthypotheseswithhierarchicalattention.InProceedingsofthe28th
plicationsfromgraphanalyticstomachinelearningbyaggregatesinrecursion.
InternationalConferenceonComputationalLinguistics:IndustryTrack.113‚Äì123.
arXivpreprintarXiv:1909.08249(2019).
[32] MingdaLi,CristianLumezanu,BoZong,andHaifengChen.2018.Deeplearning
[7] BhuwanDhingra,LihongLi,XiujunLi,JianfengGao,Yun-NungChen,Faisal
ipnetworkrepresentations.InProceedingsofthe2018WorkshoponBigData
Ahmed, andLiDeng.2016. End-to-end reinforcementlearningofdialogue
AnalyticsandMachineLearningforDataCommunicationNetworks.33‚Äì39.
agentsforinformationaccess.arXivpreprintarXiv:1609.00777(2016).
[33] MingdaLi,WeitongRuan,XinyueLiu,LucaSoldaini,WaelHamza,andCheng-
[8] Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra,
weiSu.2020.Improvingspokenlanguageunderstandingbyexploitingasrn-best
AlexanderMiller,ArthurSzlam,andJasonWeston.2015.Evaluatingprerequisite
hypotheses.arXivpreprintarXiv:2001.05284(2020).
qualitiesforlearningend-to-enddialogsystems.arXivpreprintarXiv:1511.06931
[34] MingdaLi,HongzhiWang,andJianzhongLi.2019. Miningconditionalfunc-
(2015).
tionaldependencyrulesonbigdata.BigDataMiningandAnalytics3,1(2019),
[9] Ond≈ôejDu≈°ekandFilipJurƒç√≠ƒçek.2016. Acontext-awarenaturallanguagegen-
68‚Äì84.
eratorfordialoguesystems.arXivpreprintarXiv:1608.07076(2016).
[35] MingdaLi,BoZong,CristianLumezanu,andHaifengChen.2019. LearningIP
[10] MihailEricandChristopherDManning.2017. Key-ValueRetrievalNetworks
networkrepresentations.ACMSIGCOMMComputerCommunicationReview48,
forTask-OrientedDialogue.arXivpreprintarXiv:1705.05414(2017).
5(2019),48‚Äì54.
[11] HaoFang,HaoCheng,ElizabethClark,ArielHoltzman,MaartenSap,MariOs-
[36] XuijunLi,Yun-NungChen,LihongLi,andJianfengGao.2017.End-to-endtask-
tendorf,YejinChoi,andNoahASmith.2017. SoundingBoard‚ÄìUniversityof
completionneuraldialoguesystems.arXivpreprintarXiv:1703.01008(2017).
Washington‚ÄôsAlexaPrizeSubmission.AlexaPrizeProceedings(2017).
[37] YoufuLi,MingdaLi,LingDing,andMatteoInterlandi.2018. Rios:Runtime
[12] XinyuFu,JianiZhang,ZiqiaoMeng,andIrwinKing.2020. Magnn:Metapath
integratedoptimizerforspark.InProceedingsoftheACMSymposiumonCloud
aggregatedgraphneuralnetworkforheterogeneousgraphembedding.InPro-
Computing.275‚Äì287.
ceedingsofTheWebConference2020.2331‚Äì2341.
[38] YoufuLi,JinWang,MingdaLi,AriyamDas,JiaqiGu,andCarloZaniolo.2021.
[13] MarjanGhazvininejad,ChrisBrockett,Ming-WeiChang,BillDolan,Jianfeng
Kddlog: Performance and scalabilityin knowledge discovery by declarative
Gao,Wen-tauYih,andMichelGalley.2017.Aknowledge-groundedneuralcon-
querieswithaggregates.In2021IEEE37thInternationalConferenceonDataEn-
versationmodel.arXivpreprintarXiv:1702.01932(2017).
gineering(ICDE).IEEE,1260‚Äì1271.
[14] SayanGhosh,MathieuChollet,EugeneLaksana,Louis-PhilippeMorency,and
[39] Kevin Lin, Dianqi Li, Xiaodong He, Ming-Ting Sun, and Zhengyou Zhang.
StefanScherer.2017. Affect-lm:Aneurallanguagemodelforcustomizableaf-
2017. AdversarialRankingforLanguageGeneration.InAdvancesinNeural
fectivetextgeneration.arXivpreprintarXiv:1704.06851(2017).
Information ProcessingSystems30: Annual ConferenceonNeural Information
[15] MuhammadAli Gulzar,MatteoInterlandi, XueyuanHan, Mingda Li,Tyson
ProcessingSystems2017,4-9December2017,LongBeach,CA,USA.3158‚Äì3168.
Condie,andMiryungKim.2017. Automateddebuggingindata-intensivescal-
http://papers.nips.cc/paper/6908-adversarial-ranking-for-language-generation
ablecomputing.InProceedingsofthe2017SymposiumonCloudComputing.520‚Äì
[40] ZacharyLipton,XiujunLi,JianfengGao,LihongLi,FaisalAhmed,andLiDeng.
534.
2017.BBQ-Networks:EfficientExplorationinDeepReinforcementLearningfor
[16] RChulakaGunasekara,DavidNahamoo,LazarosCPolymenakos,JatinGanho-
Task-OrientedDialogueSystems.arXivpreprintarXiv:1711.05715(2017).
tra,andKshitijPFadnis.[n.d.]. Quantized-DialogLanguageModelforGoal-
[41] XinyueLiu,MingdaLi,LuoxinChen,PrashanWanigasekara,WeitongRuan,
OrientedConversationalSystems.([n.d.]).
HaidarKhan,WaelHamza,andChengweiSu.2021. Asrn-bestfusionnets.In
ICASSP2021-2021IEEEInternationalConferenceonAcoustics,SpeechandSignal
0https://developer.amazon.com/alexaprize/ Processing(ICASSP).IEEE,7618‚Äì7622.
Conference‚Äô17,July2017,Washington,DC,USA ZijunXue,RuiruiLi,andMingdaLi
[42] RyanLowe,NissanPow,IulianSerban,LaurentCharlin,andJoellePineau.2015. [66] WeiyanWang,YuxiangWU,YuZhang,ZhongqiLu,KaixiangMo,andQiang
Incorporatingunstructuredtextualknowledgesourcesintoneuraldialoguesys- Yang.2017.IntegratingUserandAgentModels:ADeepTask-OrientedDialogue
tems.InNeuralInformationProcessingSystemsWorkshoponMachineLearning System.arXivpreprintarXiv:1711.03697(2017).
forSpokenLanguageUnderstanding. [67] Tsung-HsienWen,DavidVandyke,NikolaMrksic,MilicaGasic,LinaMRojas-
[43] RyanThomasLowe,NissanPow,IulianVladSerban,LaurentCharlin,Chia-Wei Barahona, Pei-Hao Su, Stefan Ultes, and Steve Young. 2016. A network-
Liu,andJoellePineau.2017. Trainingend-to-enddialoguesystemswiththe based end-to-end trainable task-oriented dialogue system. arXiv preprint
ubuntudialoguecorpus.Dialogue&Discourse8,1(2017),31‚Äì65. arXiv:1604.04562(2016).
[44] YiLuan,ChrisBrockett,BillDolan,JianfengGao,andMichelGalley.2017.Multi- [68] PhillipKuznetsovWilliamH.Guss,JamesBartlett.2017.Eigen:AStepTowards
Task Learningfor Speaker-Role Adaptation in NeuralConversationModels. ConversationalAI.AlexaPrizeProceedings(2017).
arXivpreprintarXiv:1710.07388(2017). [69] JasonDWilliamsandGeoffreyZweig.2016. End-to-end lstm-baseddialog
[45] YiLuan,YangfengJi,andMariOstendorf.2016.LSTMbasedConversationMod- controloptimizedwithsupervisedandreinforcementlearning. arXivpreprint
els.arXivpreprintarXiv:1603.09457(2016). arXiv:1606.01269(2016).
[46] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis [70] JiachengWu,YongZhang,JinWang,ChunbinLin,YingjiaFu,andChunxiao
Antonoglou,DaanWierstra,andMartinA.Riedmiller.2013.PlayingAtariwith Xing.2019. ImprovingDistributedSimilarityJoininMetricSpacewithError-
DeepReinforcementLearning. CoRRabs/1312.5602(2013). arXiv:1312.5602 boundedSampling.arXivpreprintarXiv:1905.05981(2019).
http://arxiv.org/abs/1312.5602 [71] JiachengWu,YongZhang,JinWang,ChunbinLin,YingjiaFu,andChunxiao
[47] LiliMou,YipingSong,RuiYan,GeLi,LuZhang,andZhiJin.2016. Sequence Xing.2019. Scalablemetricsimilarityjoinusingmapreduce.In2019IEEE35th
tobackwardandforwardsequences:Acontent-introducingapproachtogener- InternationalConferenceonDataEngineering(ICDE).IEEE,1662‚Äì1665.
ativeshort-textconversation.arXivpreprintarXiv:1607.00970(2016). [72] JunYin,XinJiang,ZhengdongLu,LifengShang,HangLi,andXiaomingLi.2015.
[48] NikolaMrk≈°iƒá,DiarmuidOS√©aghdha,BlaiseThomson,MilicaGa≈°iƒá,Pei-HaoSu, Neuralgenerativequestionanswering.arXivpreprintarXiv:1512.01337(2015).
DavidVandyke,Tsung-HsienWen,andSteveYoung.2015.Multi-domaindialog [73] PengchengYin,ZhengdongLu,HangLi,andBenKao.2015. Neuralenquirer:
statetrackingusingrecurrentneuralnetworks.arXivpreprintarXiv:1506.07190 Learningtoquerytables.arXivpreprintarXiv:1512.00965(2015).
(2015). [74] SteveYoung,MilicaGa≈°iƒá,BlaiseThomson,andJasonDWilliams.2013.Pomdp-
[49] Baolin Peng, Xiujun Li, Lihong Li, Jianfeng Gao, Asli Celikyilmaz, Sungjin basedstatisticalspokendialogsystems:Areview.Proc.IEEE101,5(2013),1160‚Äì
Lee, and Kam-Fai Wong. 2017. Composite Task-Completion Dialogue Pol- 1179.
icyLearningviaHierarchicalDeepReinforcementLearning. arXivpreprint [75] TomYoung,ErikCambria,ItiChaturvedi,MinlieHuang,HaoZhou,andSub-
arXiv:1704.03084(2017). hamBiswas.2017. Augmentingend-to-enddialogsystemswithcommonsense
[50] MartinRadfar,AthanasiosMouchtaris,andSiegfriedKunzmann.2020. End-to- knowledge.arXivpreprintarXiv:1709.05453(2017).
endneuraltransformerbasedspokenlanguageunderstanding. arXivpreprint [76] LantaoYu,WeinanZhang,JunWang,andYongYu.2017. SeqGAN:Sequence
arXiv:2008.10984(2020). GenerativeAdversarialNetswithPolicyGradient..InAAAI.2852‚Äì2858.
[51] JenniferMRoddandMatthewHDavis.2017. Howtostudyspokenlanguage [77] CarloZaniolo,AriyamDas,JiaqiGu,YoufuLi,JinWang,etal.2019. Mono-
understanding:asurveyofneuroscientificmethods.,805‚Äì817pages. tonicpropertiesofcompletedaggregatesinrecursivequeries. arXivpreprint
[52] IulianVladSerban,AlessandroSordoni,RyanLowe,LaurentCharlin,Joelle arXiv:1910.08888(2019).
Pineau,AaronCCourville,andYoshuaBengio.2017.AHierarchicalLatentVari- [78] TianchengZhao,RanZhao,andMaxineEskenazi.2017. Learningdiscourse-
ableEncoder-DecoderModelforGeneratingDialogues..InAAAI.3295‚Äì3301. leveldiversityforneuraldialogmodelsusingconditionalvariationalautoen-
[53] AlessandroSordoni,MichelGalley,MichaelAuli,ChrisBrockett,YangfengJi, coders.arXivpreprintarXiv:1703.10960(2017).
MargaretMitchell,Jian-YunNie,JianfengGao,andBillDolan.2015. Aneural [79] HaoZhou,MinlieHuang,TianyangZhang,XiaoyanZhu,andBingLiu.2017.
networkapproachtocontext-sensitivegenerationofconversationalresponses. Emotionalchattingmachine:emotionalconversationgenerationwithinternal
arXivpreprintarXiv:1506.06714(2015). andexternalmemory.arXivpreprintarXiv:1704.01074(2017).
[54] SainbayarSukhbaatar,JasonWeston,RobFergus,etal.2015.End-to-endmem- [80] WenyaZhu,KaixiangMo,YuZhang,ZhangbinZhu,XuezhengPeng,andQiang
orynetworks.InAdvancesinneuralinformationprocessingsystems.2440‚Äì2448. Yang.2017.FlexibleEnd-to-EndDialogueSystemforKnowledgeGroundedCon-
[55] IlyaSutskever,OriolVinyals,andQuocV.Le.2014. SequencetoSequence versation.arXivpreprintarXiv:1709.04264(2017).
LearningwithNeuralNetworks. CoRRabs/1409.3215(2014). arXiv:1409.3215
http://arxiv.org/abs/1409.3215
[56] J√∂rgTiedemann.2009.NewsfromOPUS-ACollectionofMultilingualParallel
CorporawithToolsandInterfaces. InRecentAdvancesinNaturalLanguage
Processing,N.Nicolov,K.Bontcheva,G.Angelova,andR.Mitkov(Eds.).Vol.V.
JohnBenjamins,Amsterdam/Philadelphia,Borovets,Bulgaria,237‚Äì248.
[57] CarlosToxtli,JustinCranshaw,etal.2018. UnderstandingChatbot-mediated
TaskManagement.InProceedingsofthe2018CHIConferenceonHumanFactors
inComputingSystems.ACM,58.
[58] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanNGomez,≈ÅukaszKaiser,andIlliaPolosukhin.2017. Attentionisallyou
need.Advancesinneuralinformationprocessingsystems30(2017).
[59] PavlosVougiouklis,JonathonHare,andElenaSimperl.2016.Aneuralnetwork
approachforknowledge-drivenresponsegeneration.InProceedingsofCOLING
2016,the26thInternationalConferenceonComputationalLinguistics:Technical
Papers.3370‚Äì3380.
[60] Haixun Wang. 2018. An Annotated Reading List of
Conversational AI. Retrieved Apr 5, 2018 from
https://medium.com/@haixun/a-reading-list-and-mini-survey-of-conversational-ai-32fceea97180
[61] HongzhiWang,MingdaLi,YingyiBu,JianzhongLi,HongGao,andJiacheng
Zhang.2014.Cleanix:Abigdatacleaningparfait.InProceedingsofthe23rdACM
InternationalConferenceonConferenceonInformationandKnowledgeManage-
ment.2024‚Äì2026.
[62] HongzhiWang,MingdaLi,YingyiBu,JianzhongLi,HongGao,andJiacheng
Zhang.2016.Cleanix:Aparallelbigdatacleaningsystem.ACMSIGMODRecord
44,4(2016),35‚Äì40.
[63] JinWang,ChunbinLin,MingdaLi,andCarloZaniolo.2019.AnEfficientSliding
WindowApproachforApproximateEntityExtractionwithSynonyms..InEDBT.
109‚Äì120.
[64] JinWang,ChunbinLin,MingdaLi,andCarloZaniolo.2020. Boostingapprox-
imatedictionary-basedentityextractionwithsynonyms. InformationSciences
530(2020),1‚Äì21.
[65] JinWang,JiachengWu,MingdaLi,JiaqiGu,AriyamDas,andCarloZaniolo.
2021.Formalsemanticsandhighperformanceindeclarativemachinelearning
usingDatalog.TheVLDBJournal30,5(2021),859‚Äì881.